{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for emotion score vector computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime, date, time\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a color blind friendly pallete\n",
    "CB_color_cycle = ['#377eb8','#ff7f00','#4daf4a',\n",
    "                  '#f781bf','#a65628','#984ea3',\n",
    "                  '#999999','#e41a1c','#dede00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xiaocheng's code for summary processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_summary(text):\n",
    "    \"\"\"\n",
    "    Tokenize, lemmatize, remove stopwords and punctuations from an input text.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str, input text\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str, preprocessed text\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "    return \" \".join([lemmatizer.lemmatize(word.lower()) for word in text if word.lower() not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "summaries: dictionary, with movie_id as keys and list of preprocessed words in the summary as values\n",
    "\"\"\"\n",
    "with open(\"./test_data/plot_summaries.txt\", encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "original_summaries = [x.strip() for x in content] \n",
    "summaries = [preprocess_summary(d).split() for d in original_summaries]\n",
    "summaries = {summary[0]: summary[1:] for summary in summaries}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of Xiaocheng's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading the NRC lexicon emotion intensity data\n",
    "data = pd.read_table(\"NRC-lexicon/NRC-Emotion-Intensity-Lexicon-v1-ForVariousLanguages-withZeroIntensityEntries.txt\")\n",
    "data_filt = data.iloc[:,0:9].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the emotion intensity vector for each of the movies\n",
    "emo_vector = pd.DataFrame(columns=data_filt.columns)\n",
    "emo_vector = emo_vector.drop(columns = \"English Word\")\n",
    "\n",
    "for key in summaries:\n",
    " test = pd.DataFrame(columns=data_filt.columns)\n",
    " for i in range(0,len(summaries[key])):\n",
    "  selection = data_filt[data_filt[\"English Word\"] == summaries[key][i]]\n",
    "  test = pd.concat([test, selection], ignore_index=True)\n",
    " test[\"Movie ID\"] = key\n",
    " test = test.drop(columns = \"English Word\")\n",
    " test = test.set_index(\"Movie ID\")\n",
    " test = test.groupby(\"Movie ID\").sum()\n",
    " emo_vector = pd.concat([emo_vector, test], ignore_index=False)\n",
    "\n",
    "emo_vector.reset_index(inplace=True)\n",
    "emo_vector.rename(columns={\"index\": \"Wikipedia movie ID\"}, inplace=True)\n",
    "\n",
    "# Saving the new dataframe with the emotion vectors \n",
    "emo_vector.to_csv(\"MovieIDs_emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Mya's code to parse the movie metadata:\n",
    "# Define the column names based on the metadata structure.\n",
    "column_names = [\n",
    "    \"Wikipedia movie ID\",\n",
    "    \"Freebase movie ID\",\n",
    "    \"Movie name\",\n",
    "    \"Movie release date\",\n",
    "    \"Movie box office revenue\",\n",
    "    \"Movie runtime\",\n",
    "    \"Movie languages\",\n",
    "    \"Movie countries\",\n",
    "    \"Movie genres\",\n",
    "]\n",
    "\n",
    "# Read the TSV file into a pandas DataFrame and specify that it's tab-separated.\n",
    "movie_md = pd.read_csv(\"movie.metadata.tsv\", sep='\\t', names=column_names, header=None) # <- Mya's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Mya's code to extract genres:\n",
    "# Function to extract the genres\n",
    "def extract_genres(genre_data):\n",
    "    genre_names = []\n",
    "    pattern = r'\"([^\"]+)\"\\s*:\\s*\"([^\"]+)\"'\n",
    "    matches = re.findall(pattern, genre_data)\n",
    "    for match in matches:\n",
    "        genre_names.append(match[1])  # Extract the genre name\n",
    "    return ','.join(genre_names)\n",
    "\n",
    "# Apply the function to extract genre names\n",
    "movie_md[\"Movie genres\"] = movie_md[\"Movie genres\"].apply(extract_genres)\n",
    "movie_md['Movie genres'] = movie_md['Movie genres'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joinning the dataframes by 'Wikipedia movie ID' while removing all rows in movie_md for which we\n",
    "# do not have plot summaries.\n",
    "\n",
    "emo_vector.rename(columns={\"Movie ID\": \"Wikipedia movie ID\"}, inplace=True)\n",
    "\n",
    "df = emo_vector.merge(movie_md, on='Wikipedia movie ID', how='left')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows for which the release date is unknown\n",
    "df_filtered = df[df[\"Movie release date\"].notna()]\n",
    "len(df), len(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling dates in the dataframe\n",
    "df_filtered[\"Movie release year\"] = df_filtered[\"Movie release date\"].apply(lambda x: parse(x).year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_filtered[\"Movie release year\"], df_filtered[\"anger\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like someone was really ahead of their time! Let's see who were our movie pioneers\n",
    "df_filtered[df_filtered[\"Movie release year\"] < 1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By checking on the internet I saw that the correct release date is 2010, so I can just correct the dataframe\n",
    "df_filtered.loc[26305, \"Movie release date\"] = '2010-12-02'\n",
    "df_filtered.loc[26305, \"Movie release year\"] = 2010\n",
    "df_filtered.loc[26305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with just the main genre of the movie\n",
    "df_filtered[\"Main genre\"] = df_filtered[\"Movie genres\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each genre and get the 10 most frequent genres\n",
    "top_10_genres = df_filtered['Main genre'].value_counts().head(10).index.tolist()\n",
    "\n",
    "# Filter the DataFrame to keep only movies belonging to the top 10 genres\n",
    "df_topmg = df_filtered[df_filtered['Main genre'].isin(top_10_genres)]\n",
    "\n",
    "df_topmg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the raw intensity scores per year for each on of the top 10 most common genres\n",
    "fig, ax = plt.subplots(10, 1, figsize=(20, 70))\n",
    "\n",
    "for j in range(len(top_10_genres)):\n",
    "    for i in range(1, 9):\n",
    "        sns.pointplot(\n",
    "            x=\"Movie release year\",\n",
    "            y=df_topmg.columns[i],\n",
    "            data=df_topmg[(df_topmg[\"Main genre\"] == top_10_genres[j])],\n",
    "            estimator=\"median\",\n",
    "            color=CB_color_cycle[i-1],\n",
    "            label=df_topmg.columns[i],\n",
    "            errorbar = None,\n",
    "            ax=ax[j]\n",
    "        )\n",
    "        \n",
    "        ax[j].legend(loc='upper right')\n",
    "        ax[j].set_title(top_10_genres[j])\n",
    "        ax[j].set_ylabel('Median Emotion Intensity Score')\n",
    "        ax[j].set_xlabel('Movie Release Year')\n",
    "        ax[j].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the emotion scores in percentage\n",
    "df_topmg_norm = df_topmg.copy()\n",
    "Total_score = df_topmg_norm[df_topmg_norm.columns[1:9]].sum(axis=1).copy()\n",
    "for i in range(1,9):\n",
    "    df_topmg_norm[df_topmg_norm.columns[i]] = df_topmg_norm[df_topmg_norm.columns[i]]*100/Total_score\n",
    "\n",
    "df_topmg_norm[df_topmg_norm.columns[1:9]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the normalized emotion scores per year for each on of the top 10 most common genres\n",
    "fig, ax = plt.subplots(10, 1, figsize=(20, 70), sharey = True)\n",
    "\n",
    "for j in range(len(top_10_genres)):\n",
    "    for i in range(1, 9):\n",
    "        sns.pointplot(\n",
    "            x=\"Movie release year\",\n",
    "            y=df_topmg_norm.columns[i],\n",
    "            data=df_topmg_norm[(df_topmg_norm[\"Main genre\"] == top_10_genres[j])],\n",
    "            estimator=\"median\",\n",
    "            color=CB_color_cycle[i-1],\n",
    "            label=df_topmg.columns[i],\n",
    "            #errorbar=('ci', 95),\n",
    "            errorbar = None,\n",
    "            ax=ax[j]\n",
    "        )\n",
    "        \n",
    "        ax[j].legend(loc='upper right')\n",
    "        ax[j].set_title(top_10_genres[j])\n",
    "        ax[j].set_ylabel('Median Emotion Intensity Score')\n",
    "        ax[j].set_xlabel('Movie Release Year')\n",
    "        ax[j].tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
